{"cells": [{"cell_type": "markdown", "id": "4839cd02-22e6-4e06-9617-eccba2b91eb8", "metadata": {"id": "4839cd02-22e6-4e06-9617-eccba2b91eb8", "tags": []}, "source": ["# API-201 ABC REVIEW SESSION #7\n", "\n", "**Friday, October 28**"], "outputs": []}, {"cell_type": "markdown", "id": "TpMW4e3jQarq", "metadata": {"id": "TpMW4e3jQarq"}, "source": ["# Table of Contents\n", "1. [Lecture Recap](#Lecture-Recap)\n", "2. [Exercise - Project STAR Part 2](#Exercises)"], "outputs": []}, {"cell_type": "markdown", "id": "G7rWjus2gvIV", "metadata": {"id": "G7rWjus2gvIV"}, "source": ["# Lecture Recap <a class=\"anchor\" id=\"Lecture-Recap\"></a>"], "outputs": []}, {"cell_type": "markdown", "id": "4525c9cf-387b-4fa9-90d4-86dff37fcd79", "metadata": {}, "source": ["## Confidence intervals"], "outputs": []}, {"cell_type": "markdown", "id": "f838d456-40c0-4e2d-87e9-452800eef977", "metadata": {}, "source": ["Suppose there is some mean ***$\\mu$*** that we want to measure. We usually don't have access to information for all the population, so we estimate ***$\\mu$*** by computing the mean ***$\\hat{\\mu}$*** in a random sample. \n", "\n", "The sample mean ***$\\hat{\\mu}$*** is random, as it may produce a different estimate if we apply it to a different sample. The **sampling distribution** is the distribution of the sample mean ***$\\hat{\\mu}$***. In other words, it is a probability distribution formed by the estimates we obtain from calculating the mean for different samples from the population of interest.\n", "\n", "The sample mean ***$\\hat{\\mu}$*** is a random variable, so it has an expected value and a standard deviation. The **Central Limit Theorem** states that for a large enough sample (n > 30), the distribution of ***$\\hat{\\mu}$*** is approximately normal:\n", "\\begin{align*}\n", "N(\\mu,\\frac{\\sigma}{\\sqrt{n}})\n", "\\end{align*}\n", "\n", "The sampling distribution allows us to construct a **95% confidence interval around our point estimate**. 95% of all possible confidence intervals will contain the true value of the population parameter. \n", "\n", "If the sampling distribution is normal, then we can construct a 95% confidence interval around ***$\\hat{\\mu}$*** by using the mean and standard deviation of ***$\\hat{\\mu}$***. However, given that we don't know ***$\\mu$***, we use both the sample proportion and the estimated standard error instead, such that: \n", "\\begin{align*}\n", "CI = \\hat{\\mu} \\pm 2 SD(\\hat{\\mu})\n", "\\end{align*}\n", "\n", "where:\n", "\\begin{align*}\n", "SD(\\hat{\\mu}) = \\frac{\\hat{\\sigma}}{\\sqrt{n}}\n", "\\end{align*}"], "outputs": []}, {"cell_type": "markdown", "id": "554ba634-f799-4bab-86d0-d28d30522613", "metadata": {}, "source": ["## Constructing confidence intervals"], "outputs": []}, {"cell_type": "markdown", "id": "8056e1b9-63b0-44a7-832a-82a136d33b73", "metadata": {}, "source": ["Recall that an **estimate** is our best guess of the true value of the population parameter. There are multiple types of parameters that we could be interested in estimating. For example:\n", "1. Proportion: Proportion of vaccinated people that got Covid.\n", "2. Mean: Average consumption for people that had access to a microfinance program in India.\n", "3. Difference in proportions: Difference in Covid infection rates between those who got vaccinated and those who didn\u2019t.\n", "4. Difference in means: Difference in average consumption between treatment\n", "and control groups of a microfinance program in India.\n", "\n", "We can use the sampling distribution of our estimator to tell us how confident we are in our estimate. The table below contains the information we need to construct a confidence interval for each of these parameters:\n", "\n", "|  Population parameter | Sample parameter | Mean of sampling distribution | Standard deviation of sampling distribution\n", "| --- | --- | --- | --- \n", "| $p$ | $\\hat{p}$  |  $E(\\hat{p})= p$ | $\\sqrt{\\frac{p(1-p)}{n}}$\n", "| $\\mu$ | $\\hat{\\mu}$ |  $E(\\hat{\\mu})= \\mu$ | $\\frac{\\sigma}{\\sqrt{n}}$\n", "| $p_1 - p_2$ | $\\hat{p_1} - \\hat{p_2}$ |  $E(\\hat{p_1} - \\hat{p_2})= p_1 - p_2$  | $\\sqrt{\\frac{p_1(1-p_1)}{n_1} + \\frac{p_2(1-p_2)}{n_2}}$\n", "| $\\mu_1 - \\mu_2$ | $\\hat{\\mu_1} - \\hat{\\mu_2}$ |  $E(\\hat{\\mu_1} - \\hat{\\mu_2})= \\mu_1 - \\mu_2$  | $\\sqrt{\\frac{\\sigma^2_1}{n_1} + \\frac{\\sigma^2_2}{n_2}}$"], "outputs": []}, {"cell_type": "markdown", "id": "c0a59ed0-8385-492f-aef8-06e5c4410919", "metadata": {}, "source": ["For example, if we wanted to estimate the difference in proportions, the 95% confidence interval has the same form as before:\n", "\\begin{align*}\n", "CI = \\hat{p_1} - \\hat{p_2} \\pm 2 SD(\\hat{p_1} - \\hat{p_2})\n", "\\end{align*}\n", "\n", "Plugging in the standard deviation of the difference in proportions, we get:\n", "\n", "\\begin{align*}\n", "CI = \\hat{p_1} - \\hat{p_2} \\pm 2 \\sqrt{\\frac{\\hat{p_1}(1-\\hat{p_1})}{n_1} + \\frac{\\hat{p_2}(1-\\hat{p_2})}{n_2}}\n", "\\end{align*}"], "outputs": []}, {"cell_type": "markdown", "id": "9b9b2c8c-bc96-446f-8523-fd76dcb448ef", "metadata": {}, "source": ["## Statistical significance"], "outputs": []}, {"cell_type": "markdown", "id": "34353223-a6e1-468e-910b-fb3a1d253e9b", "metadata": {}, "source": ["**Hypothesis testing** consists in posing a hypothesis concerning the value of a population parameter, drawing a sample from the population _under the assumption this hypothesis is true_, and then\n", "assessing the estimate with respect to the hypothesis posed. The observed value is **statistically significant** if it is unlikely under the null hypothesis. In other words, it doesn\u2019t fall within the middle 95% of the null sampling distribution.\n", "\n", "For example, suppose the Scranton branch of a large paper company wants to test that its outgoing shipment of letter-sized paper is 8.5 inches wide on average. The company randomly samples 100 pieces of paper and finds that the average width is 8.45 inches with a standard deviation of 0.1 inches. \n", "\n", "* The null hypothesis is $\\mu = 8.5$. \n", "* $n = 100$\n", "* $\\hat\\mu = 8.45$\n", "* $\\hat\\sigma = 0.1$.\n", "\n", "The standard error of the mean is $\\frac{\\hat\\sigma}{\\sqrt{n}} = \\frac{0.1}{\\sqrt{100}} = 0.01$ Therefore the 95% confidence interval is $[8.43, 8.47]$.\n", "\n", "The branch found that the mean width in the sample is less than 8.5, but this could just be the result of sample fluctuations. They want to know whether we have enough evidence to reject the null hypothesis that $\\mu = 8.5$, so they ask: \"if the average size truly is 8.5 inches, how unlikely is it to observe this sample mean?\"\n", "\n", "An estimate is statistically significant if it is at least two standard deviations away from the null hypothesis, so that we reject only the most extreme 5 percent of values. The confidence interval consists of those points within two standard deviations of the estimate. So an estimate is statistically significant if its confidence interval does not contain the null hypothesis. \n", "\n", "In the paper example, the confidence interval does not contain 8.5, so the branch **rejects this null hypothesis.** If instead the confidence interval was wide enough to include 8.5, they would **fail to reject the null hypothesis**. This could either be because the null hypothesis is true, or because the sample size is not large enough to reject it. For example, if the true mean was $\\mu = 8.4999$, the null hypothesis is technically false but because the mean is so similar, we would need to have a very large sample size to reject the null hypothesis with regularity. \n", "\n", "The **p-value** is the probability of obtaining an estimate as extreme or more extreme than the one we obtained assuming our null hypothesis is true. A result is statistically significant if the p-value is less than 0.05. In other words, if the null hypothesis were true, we are unlikely to have obtained our result. \n", "\n", "We compute p-values using z-scores. The z-score tells us how many standard deviations our estimate is from the null hypothesis:\n", "\\begin{align*}\n", "z = \\frac{x-\\mu_0}{s}\n", "\\end{align*}\n", "\n", "where $\\mu_0$ is the null hypothesis and $s$ is the standard error.\n", "\n", "We convert z-scores to p-values with the **pnorm** function in R. For any number z, pnorm(z) returns the probability that the normal random variable is less than z standard deviations below its mean. In order to get both of the \"tails\" on the extremes of our estimate, we need to make sure we use a negative Z-score and double the value to account for both tails. So if our z-score is z, we can calculate the p-value as `2 * pnorm(-abs(z))`."], "outputs": []}, {"cell_type": "markdown", "id": "3676a159-a22f-429f-b9a5-509ed5fa8a60", "metadata": {}, "source": ["## Calculating p-values in R"], "outputs": []}, {"cell_type": "markdown", "id": "f3ce95ee-7617-43e6-9267-5ab4f2b794ac", "metadata": {}, "source": ["Suppose that we were testing whether the microfinance has an effect on consumption. The null hypothesis is that the difference in means is equal to 0, and the null sampling distribution is plotted below. If you find a z-score equal to 2, what is the p-value associated with that z-score? Is your estimate of the difference in means significant?"], "outputs": []}, {"cell_type": "code", "execution_count": 0, "id": "44d78d89-0765-416f-b856-99b0fd21ea7b", "metadata": {}, "outputs": [], "source": ["# Plot a standard normal distribution\n", "library(tidyverse)\n", "\n", "data <- tibble(x = seq(-4, 4, .05), dens = dnorm(x))\n", "\n", "ggplot(data, aes(x = x, y = dens)) + \n", "    geom_line() +\n", "    geom_area(data = filter(data, x <= -2), alpha = .5) +\n", "    geom_area(data = filter(data, x >= 2), alpha = .5) "]}, {"cell_type": "code", "execution_count": 0, "id": "b85f409b-33f3-4f24-91a1-fd47e615b432", "metadata": {}, "outputs": [], "source": ["# Pnorm\n", "2 * pnorm(-abs(2))"]}, {"cell_type": "markdown", "id": "4d55d0e1-c2fe-4843-b135-02eff977f881", "metadata": {"id": "Nrdsx61qeOTu"}, "source": ["# Exercise: Project STAR Part 2<a class=\"anchor\" id=\"Exercises\"></a>"], "outputs": []}, {"cell_type": "markdown", "id": "fb85f192-e80a-4c97-a3fe-1a72973dd9a6", "metadata": {"id": "hR1Oc6jve7ui"}, "source": ["**From last week:** The Project STAR (for Student-Teacher Achievement Ratio) was designed to determine the effect of smaller class size in the earliest grades on short-term and long-term pupil performance ([source](https://dataverse.harvard.edu/dataset.xhtml?persistentId=hdl:1902.1/10766)). Over 7,000 students in 79 schools across the state of Tennessee were randomly assigned into one of three interventions: small class (13 to 17 students per teacher), regular class (22 to 25 students per teacher), and regular-with-aide class (22 to 25 students with a full-time teacher's aide). Classroom teachers were also randomly assigned to the classes they would teach. The interventions were initiated as the students entered school in kindergarten and continued through third grade. \n", "\n"], "outputs": []}, {"cell_type": "markdown", "id": "8e17448d-d3b1-48b7-9682-2dc34c2d7847", "metadata": {"id": "IR0kIBTihABJ"}, "source": ["In this exercise, we are going to use data from Project STAR to assess whether there is a statistically significant impact of class sizes on learn about the pupils involved in the project through visualization and measure the association between classroom size and student achievement.\n", "\n", "Unlike last class, the data has been aggregated at the teacher level so that scores are averages across all students taught by that teacher. \n", "\n", "[Download the data using this link.](https://github.com/5harad/API201-students/raw/main/review_sessions/review_7/STAR_teachers.xlsx)"], "outputs": []}, {"cell_type": "markdown", "id": "ec71c973-faaa-40e6-8511-5c2bd4d206b2", "metadata": {}, "source": ["## Data Dictionary\n", "* `teacher_id`: kindergarten teacher ID\n", "* `class_type`: kindergarten class type; S - Small, R - Regular/Large\n", "* `reading_score`: average kindergarten reading score\n", "* `math_score`: average kindergarten math score"], "outputs": []}, {"cell_type": "markdown", "id": "7f2a8923-f4b9-4202-8069-f0ef3bd2932a", "metadata": {"id": "uITJCSSUgv7E"}, "source": ["**1. Upload the Excel file `STAR_teachers.xlsx` to Google Colab and use `read_excel` to read its first worksheet as a new table called `star_teachers`. Examine the first 10 rows of the data.**"], "outputs": []}, {"cell_type": "code", "execution_count": 0, "id": "wkttULQHcYYW", "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 444}, "id": "wkttULQHcYYW", "outputId": "9545672a-2ec6-41e1-b5ad-694fb7ab51e1"}, "outputs": [], "source": ["library(tidyverse)\n", "library(readxl)\n", "\n", "# Your answer here!\n", "\n"]}, {"cell_type": "markdown", "id": "298df12a-1ae7-4255-84f4-0add994e2451", "metadata": {}, "source": ["**2. Calculate the number of teachers and the mean and variance of reading score by class type. Which class type has a higher average reading score? Which class type has greater variance in reading score?** \n"], "outputs": []}, {"cell_type": "code", "execution_count": 0, "id": "e3264aa0-e9ef-4b5c-a471-2b3910204019", "metadata": {}, "outputs": [], "source": ["# Your answer here!\n", "\n"]}, {"cell_type": "markdown", "id": "4a50b7be-4231-43df-a68d-801c57641267", "metadata": {}, "source": ["**3. Suppose $\\hat\\mu_R$ is the sample mean of the reading score in regular classes and $\\hat\\mu_S$ is the sample mean in small classes. Using your results from (2), calculate the difference in sample means and the standard error of $\\hat\\mu_S - \\hat\\mu_R$.**\n", "\n", "Recall that $SE(\\hat\\mu_S - \\hat\\mu_R) = \\sqrt{\\frac{\\hat\\sigma_S^2}{n_S} + \\frac{\\hat\\sigma_R^2}{n_R}}$ where $\\hat\\sigma_S^2$ and $\\hat\\sigma_R^2$ are the sample variances and $n_S$ and $n_R$ are the sample sizes."], "outputs": []}, {"cell_type": "code", "execution_count": 0, "id": "0455a804-8e97-40ce-b860-ddb5656cd2ea", "metadata": {}, "outputs": [], "source": ["# Your answer here!\n", "\n"]}, {"cell_type": "markdown", "id": "e2097ccf-05ae-4394-84e6-24f5ba8cbb1e", "metadata": {}, "source": ["**4. What is the 95% confidence interval of $\\mu_S - \\mu_R$?**"], "outputs": []}, {"cell_type": "code", "execution_count": 0, "id": "0bb9741e-7445-456c-8dcd-96b9dcc106fe", "metadata": {}, "outputs": [], "source": ["# Your answer here!\n", "\n"]}, {"cell_type": "markdown", "id": "d80ffbc6-de30-4c00-b339-f63683acd57c", "metadata": {}, "source": ["**5. What is the Z-score corresponding to the null hypothesis $\\mu_S - \\mu_R = 0$?**"], "outputs": []}, {"cell_type": "code", "execution_count": 0, "id": "5631c07f-f615-44ac-abec-11f605cbc997", "metadata": {}, "outputs": [], "source": ["# Your answer here!\n", "\n"]}, {"cell_type": "markdown", "id": "1815bfd6-d857-4c28-89f8-b6c9045699a1", "metadata": {}, "source": ["**6. What is the p-value corresponding to the Z-score? Is the difference in means statistically significant?**"], "outputs": []}, {"cell_type": "code", "execution_count": 0, "id": "2d0e2cd8-d7a7-41ae-9f09-b62d6a0b3ad6", "metadata": {}, "outputs": [], "source": ["# Your answer here!\n", "\n"]}], "metadata": {"colab": {"collapsed_sections": [], "provenance": [], "name": "review_7_exercises.ipynb"}, "kernelspec": {"display_name": "R", "language": "R", "name": "ir"}, "language_info": {"codemirror_mode": "r", "file_extension": ".r", "mimetype": "text/x-r-source", "name": "R", "pygments_lexer": "r", "version": "4.1.2"}}, "nbformat": 4, "nbformat_minor": 5}